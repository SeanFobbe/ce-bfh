---
title: "Codebook | Corpus der Entscheidungen des Bundesfinanzhofs (CE-BFH)"
author: Seán Fobbe
geometry: margin=3cm
papersize: a4
fontsize: 11pt
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    pandoc_args: --listings
    includes:
      in_header: ../tex/Preamble_DE.tex
      before_body: [../temp/Definitions.tex, ../tex/Titlepage_Codebook.tex]
bibliography: ../temp/packages.bib
nocite: '@*'
---


```{r, setup, include=FALSE}
knitr::opts_chunk$set(fig.path = file.path("..", "analysis/"),
                      dev = config$fig$format,
                      dpi = config$fig$dpi,
                      fig.align = config$fig$align,
                      echo = FALSE,
                      warning = FALSE,
                      message = FALSE)

```


```{r, echo = FALSE}
tar_load(latexdefs)
tar_load(dt.meta)
tar_load(files.pdf)
tar_load(files.txt)
tar_load(files.html)
tar_load(variables.codebook)
tar_load(lingstats.summary)
tar_load(az.brd)
tar_load(igraph_citations)
```



# Einführung

 Der **Bundesfinanzhof (BFH)** ist einer der fünf obersten Gerichtshöfe des Bundes und steht an der Spitze der Finanzgerichtsbarkeit der Bundesrepublik Deutschland (Art. 95 Abs. 1 GG, §§ 2, 10 f. FGO). Der BFH ist die höchste Instanz in Steuer- und Zollsachen und entscheidet über Revisionen gegen Urteile der Finanzgerichte, gegen urteilsgleiche Entscheidungen und Beschwerden gegen andere Entscheidungen der Finanzgerichte (§ 36 FGO).\footnote{Der Finanzrechtsweg ist vergleichsweise kurz: in erster Instanz entscheiden die Finanzgerichte (§ 35 FGO) und es steht im Anschluss nur noch die Anrufung des BFH offen (§ 36 FGO).} Er wurde mit dem \enquote{Gesetz über den  Bundesfinanzhof} vom 29. Juni 1950 errichtet und hat seinen Sitz in München (§ 2 FGO).

Im Jahr 2022 sind am Bundesfinanzhof 11 Senate eingerichtet, bestehend aus ca. 60 Richter:innen.\footnote{\url{https://www.bundesfinanzhof.de/de/gericht/organisation/}.} Zudem besteht ein Großer Senat, dem Richter:innen aller Senate angehören. Präsident:in und Vizepräsident:in vertreten das Gericht nach Außen. Entscheidungen der Senate ergehen in einer Besetzung von 5 Richter:innen, Beschlüsse außerhalb der mündlichen Verhandlung können von 3 Richter:innen getroffen werden (§ 10 Abs. 3 FGO). Der Große Senat besteht aus Gerichtspräsident:in und einer Richter:in jedes Senates, in dem der Vorsitz nicht von der Gerichtspräsident:in geführt wird (§ 11 Abs. 5 FGO), d.h. aktuell 11 Mitgliedern. Zu Beginn jeden Jahres bestimmt das Präsidium des Gerichts die thematische Geschäftsverteilung zwischen den Senaten. 

Wieso dieser Datensatz? Die quantitative Analyse von juristischen Texten, insbesondere denen des BFH, ist in den deutschen Rechtswissenschaften ein noch junges und kaum bearbeitetes Feld.\footnote{Besonders positive Ausnahmen finden sich unter: \url{https://www.quantitative-rechtswissenschaft.de/}} Zu einem nicht unerheblichen Teil liegt dies auch daran, dass die Anzahl an frei nutzbaren Datensätzen außerordentlich gering ist.
 
Die meisten hochwertigen Datensätze lagern (fast) unerreichbar in kommerziellen Datenbanken und sind wissenschaftlich gar nicht oder nur gegen Entgelt zu nutzen. Frei verfügbare Datenbanken wie \emph{Opinio Iuris}\footnote{\url{https://opinioiuris.de/}} und \emph{openJur}\footnote{\url{https://openjur.de/}} verbieten ausdrücklich das maschinelle Auslesen der Rohdaten. Wissenschaftliche Initiativen wie der Juristische Referenzkorpus (JuReKo) sind nach jahrelanger Arbeit hinter verschlossenen Türen verschwunden.
 
In einem funktionierenden Rechtsstaat muss die Rechtsprechung öffentlich, transparent und nachvollziehbar sein. Im 21. Jahrhundert bedeutet dies auch, dass sie systematischer Überprüfung mittels quantitativen Analysen zugänglich sein muss. Der Erstellung und Aufbereitung des Datensatzes liegen daher die Prinzipien der allgemeinen Verfügbarkeit durch Urheberrechtsfreiheit, strenge Transparenz und vollständige wissenschaftliche Reproduzierbarkeit zugrunde. Die FAIR-Prinzipien (Findable, Accessible, Interoperable and Reusable) für freie wissenschaftliche Daten inspirieren sowohl die Konstruktion, als auch die Art der Publikation.\footnote{Wilkinson, M., Dumontier, M., Aalbersberg, I. et al. The FAIR Guiding Principles for Scientific Data Management and Stewardship. Sci Data 3, 160018 (2016). \url{https://doi.org/10.1038/sdata.2016.18}}






# Nutzung

Die Daten sind in offenen, interoperablen und weit verbreiteten Formaten (CSV, TXT, PDF) veröffentlicht. Sie lassen sich grundsätzlich mit allen modernen Programmiersprachen (z.B. Python oder R), sowie mit grafischen Programmen nutzen.

 **Wichtig:** Nicht vorhandene Werte sind sowohl in den Dateinamen als auch in der CSV-Datei mit "NA" codiert.


## CSV-Dateien

Am einfachsten ist es die **CSV-Dateien** einzulesen. CSV\footnote{Das CSV-Format ist in RFC 4180 definiert, siehe \url{https://tools.ietf.org/html/rfc4180}} ist ein einfaches und maschinell gut lesbares Tabellen-Format. In diesem Datensatz sind die Werte komma-separiert. Jede Spalte entspricht einer Variable, jede Zeile einer Entscheidung. Die Variablen sind unter Punkt \ref{variablen} genauer erläutert.

Zum Einlesen empfehle ich für **R** das package **data.table** (via CRAN verfügbar). Dessen Funktion **fread()** ist etwa zehnmal so schnell wie die normale **read.csv()**-Funktion in Base-R. Sie erkennt auch den Datentyp von Variablen sicherer. Ein Beispiel:


```{r eval = FALSE, echo = TRUE}
library(data.table)
dt <- fread("filename.csv")
```



## TXT-Dateien

Die **TXT-Dateien** inklusive Metadaten können zum Beispiel mit **R** und dem package **readtext** (via CRAN verfügbar) eingelesen werden. Ein Vorschlag:

```{r eval = FALSE, echo = TRUE}
library(readtext)
df <- readtext("./*.txt",
               docvarsfrom = "filenames", 
               docvarnames = c("gericht",
                               "bfhe",
                               "datum",
                               "spruchkoerper_az",
                               "registerzeichen",
                               "eingangsnummer",
                               "eingangsjahr_az",
                               "zusatz_az",
                               "bfh_id",
                               "kollision"),
               dvsep = "_", 
               encoding = "UTF-8")
```








# Konstruktion



## Beschreibung des Datensatzes

Dieser Datensatz ist eine digitale Zusammenstellung von möglichst allen begründeten Entscheidungen, die auf der amtlichen Internetpräsenz des Bundesfinanzhofs (BFH) am jeweiligen Stichtag veröffentlicht waren. Die Stichtage für jede Version entsprechen exakt der Versionsnummer.

Zusätzlich zu den aufbereiteten maschinenlesbaren Formaten (HTML und CSV) sind die PDF-Daten enthalten, damit Analyst:innen gegebenenfalls eine unabhängige Konvertierung vornehmen können. Die PDF-Rohdaten wurden inhaltlich nicht verändert und nur die Dateinamen angepasst, um die Lesbarkeit für Mensch und Maschine zu verbessern.

Speziell an Praktiker:innen richten sich die PDF-Sammlungen aller in der amtlichen Sammlung abgedruckten Entscheidungen (V-Entscheidungen).



## Datenquellen

\begin{centering}
\begin{longtable}{P{5cm}p{9cm}}

\toprule

 Datenquelle & Fundstelle \\

\midrule

 Primäre Datenquelle & \url{https://www.bundesfinanzhof.de}\\
 Source Code & \url{\softwareversionurldoi}\\
 Registerzeichen & \url{\aktenzeichenurldoi}\\

\bottomrule

\end{longtable}
\end{centering}


Die Tabelle der Registerzeichen und der ihnen zugeordneten Verfahrensarten stammt aus dem folgenden Datensatz: "Seán Fobbe (2021). Aktenzeichen der Bundesrepublik Deutschland (AZ-BRD). Version 1.0.1. Zenodo. DOI: 10.5281/zenodo.4569564."





## Sammlung der Daten

Die Daten wurden unter Beachtung des Robot Exclusion Standard (RES) gesammelt. Der Abruf geschieht ausschließlich über TLS-verschlüsselte Verbindungen. Die Entscheidungen sind laut dem Gericht anonymisiert, aber ungekürzt.




```{r, CE-BFH_Pipeline_Graph, fig.width = 12, fig.height = 18, fig.pos = "p", fig.cap = "Der vollständige Prozess der Datensatz-Kompilierung."}

edgelist <- tar_network(targets_only = TRUE)$edges
setDT(edgelist)

g  <- igraph::graph.data.frame(edgelist,
                               directed = TRUE)


ggraph(g,
       'sugiyama') + 
    geom_edge_diagonal(colour = "grey")+
    geom_node_point()+
    geom_node_text(aes(label = name),
                   size = 2,
                   repel = TRUE)+
    theme_void()+
    labs(
        title = paste(prefix.figuretitle,
                      "| Vollständiger Prozess der Datensatz-Kompilierung"),
        caption = caption
    )+
    theme(
        plot.title = element_text(size = 14,
                                  face = "bold"),
        plot.margin = margin(10, 20, 10, 10)
    )

```



## Source Code und Compilation Report

Der gesamte Source Code --- sowohl für die Erstellung des Datensatzes, als auch für dieses Codebook --- ist öffentlich einsehbar und dauerhaft erreichbar im wissenschaftlichen Archiv des CERN unter dieser Addresse hinterlegt: \softwareversionurldoi

Mit jeder Kompilierung des vollständigen Datensatzes wird auch ein umfangreicher **Compilation Report** in einem attraktiv designten PDF-Format erstellt (ähnlich diesem Codebook). Der Compilation Report enthält den kommentierten Source Code für die Daten-Pipeline, dokumentiert relevante Rechenergebnisse, gibt sekundengenaue Zeitstempel an und ist mit einem klickbaren Inhaltsverzeichnis versehen. Er ist zusammen mit dem Source Code hinterlegt. Wenn Sie sich für Details der Herstellung interessieren, lesen Sie diesen bitte zuerst.



## Grenzen des Datensatzes

Nutzer:innen sollten folgende wichtige Grenzen beachten:
 

- Der Datensatz enthält nur das, was das Gericht auch tatsächlich veröffentlicht, nämlich begründete Entscheidungen (\emph{publication bias}). 
- Es kann aufgrund technischer Grenzen bzw. Fehler sein, dass manche --- im Grunde verfügbare --- Entscheidungen nicht oder nicht korrekt abgerufen werden (\emph{automation bias}).
- Es werden HTML- und PDF-Dateien abgerufen (\emph{file type bias}). Der Text der Entscheidungen in der CSV-Datei stammt aus den HTML-Dateien. Die PDF-Dateien sind beigefügt, falls bei der Extraktion fehler auftreten sollten, sind in der Regel aber für den Gebrauch in der traditionellen Rechtswissenschaft und -praxis gedacht.
- Erst ab dem 1. Januar 2010 sind begründete Entscheidungen des Bundesfinanzhofs einigermaßen vollständig veröffentlicht (\emph{temporal bias}). Die Frequenztabellen geben hierzu genauer Auskunft.




## Urheberrechtsfreiheit von Rohdaten und Datensatz 

An den Entscheidungstexten und amtlichen Leitsätzen besteht gem. § 5 Abs. 1 UrhG kein Urheberrecht, da sie amtliche Werke sind. § 5 UrhG ist auf amtliche Datenbanken analog anzuwenden (BGH, Beschluss vom 28.09.2006, I ZR 261/03, \enquote{Sächsischer Ausschreibungsdienst}).

Alle eigenen Beiträge (z.B. durch Zusammenstellung und Anpassung der Metadaten) und damit den gesamten Datensatz stelle ich gemäß einer \emph{CC0 1.0 Universal Public Domain Lizenz} vollständig urheberrechtsfrei.




## Metadaten


### Allgemein

Die Metadaten in den Dateinamen sind größtenteils unverändert von den jeweiligen Datenbankeinträgen aus der amtlichen Datenbank des Bundesfinanzhofs entnommen. Berechnet und hinzugefügt wurden durch den Autor des Datensatzes eine Reihe weitere Variablen, sowie in den Dateinamen der PDF/TXT-Dateien Unter- und Trennstriche, um die Maschinenlesbarkeit zu erleichtern. Der volle Satz an Metadaten ist nur in den CSV-Dateien enthalten. Alle hinzugefügten Metadaten sind vollständig maschinenlesbar dokumentiert. Sie sind entweder im Source Code enthalten, mit dem Source Code zusammen dokumentiert oder über dauerhaft stabile Identifikatoren (z.B. DOI) zitiert.
 
Die Dateinamen der PDF- und TXT-Dateien enthalten Gerichtsname, die Bezeichnung als V- oder NV-entscheidung,  Datum, das offizielle Aktenzeichen, einen Zusatz zum Aktenzeichen und die vom BFH in der Datenbank genutzte einzigartige ID.



### Schema für die Dateinamen

\begin{verbatim}
 [gericht]_[bfhe]_[datum]_[spruchkoerper_az]_
 [registerzeichen]_[eingangsnummer]_[eingangsjahr_az]_[bfh_id]
\end{verbatim}


### Beispiel eines Dateinamens

\begin{verbatim}
 BFH_V_2023-07-11_X_R_17_22_STRE202310190.pdf
\end{verbatim}


## Qualitätsprüfung

Die Inhalte der Variablen wurden  strikt validiert. Die möglichen Werte der jeweiligen Variablen wurden zudem durch Frequenztabellen und Visualisierungen auf ihre Plausibilität geprüft. Insgesamt werden zusammen mit jeder Kompilierung über 30 automatisierte Tests zur Qualitätsprüfung durchgeführt. Alle Ergebnisse der Qualitätsprüfungen sind aggregiert im Robustness Checks Report, im Compilation Report und einzeln im Archiv \enquote{ANALYSE} zusammen mit dem Datensatz veröffentlicht.


## Grafische Darstellung

Die Robenfarbe der Richter:innen des Bundesfinanzhofs ist \enquote{karmesinrot}. Der Hex-Wert hierfür ist vermutlich \#7e0731. Das ist besonders bei der Erstellung thematisch passender Diagrammen hilfreich. Alle im Compilation Report und diesem Codebook präsentierten Diagramme sind in diesem karmesinrot gehalten.







# Varianten und Zielgruppen

Dieser Datensatz ist in verschiedenen Varianten verfügbar, die sich an unterschiedliche Zielgruppen richten. Zielgruppe sind nicht nur quantitativ forschende Rechtswissenschaftler:innen, sondern auch traditionell arbeitende Jurist:innen. Idealerweise müssen quantitative Methoden ohnehin immer durch qualitative Interpretation, Theoriebildung und kritische Auseinandersetzung verstärkt werden (\emph{mixed methods approach}).

Lehrende werden von den vorbereiteten Tabellen und Diagrammen besonders profitieren, die bei der Erläuterung der Charakteristika der Daten hilfreich sein können und Zeit im universitären Alltag sparen. Alle Tabellen und Diagramme liegen auch als separate Dateien vor, um sie einfach z.B. in Präsentations-Folien oder Handreichungen zu integrieren.


## CSV\_Datensatz 

Diese CSV-Datei ist die für statistische Analysen empfohlene Variante des Datensatzes. Sie enthält den Volltext aller Entscheidungen, sowie alle in diesem Codebook beschriebenen Metadaten. Jede Spalte entspricht einer Variable, jede Zeile einer Entscheidung. 

Die Texte der Entscheidungen wurden aus dem HTML-Quelltext extrahiert, nicht aus den PDF-Dateien.

**Empfohlen für Legal Tech und quantitative Forschung**


## CSV\_Metadaten

Wie die primäre CSV-Variante, nur ohne die Entscheidungstexte. Sinnvoll für Analyst:innen, die sich nur für die Metadaten interessieren und Speicherplatz sparen wollen.  Jede Spalte entspricht einer Variable, jede Zeile einer Entscheidung.


## HTML 

Diese Variante enthält die ursprünglichen HTML-Dateien, wie sie auf der Webseite des BFH präsentiert werden. Die HTML-Dateien sind die Grundlage für die CSV-Variante. Hilfreich, falls Probleme bei der Nutzung der CSV-Dateien auftreten.


## PDF 

Die PDF-Dokumente wie sie vom BFH auf der amtlichen Webseite bereitgestellt werden, jedoch verbessert durch semantisch hochwertige Dateinamen, die der leichteren Auffindbarkeit von Entscheidungen dienen. Die Dateinamen sind so konzipiert, dass sie auch für die traditionelle qualitative juristische Arbeit einen erheblichen Mehrwert bieten. 

Im Vergleich zu den CSV-Dateien enthalten die Dateinamen nur einen reduzierten Umfang an Metadaten, um Kompatibilitätsprobleme zu vermeiden und die Lesbarkeit zu verbessern. 

Neben dem vollen Datensatz ist für Praktiker:innen auch eine Variante aufbereitet, die nur \emph{V-Entscheidungen} der amtlichen Sammlung enthalten.

**Empfohlen für traditionelle juristische Forschung**



## TXT 

Diese Variante enthält die vollständigen, aus den PDF-Dateien extrahierten Entscheidungstexte, aber nur einen reduzierten Umfang an Metadaten, der dem der PDF-Dateien entspricht. Die TXT-Dateien sind optisch an das Layout der PDF-Dateien angelehnt. 

Geeignet für qualitativ arbeitende Forscher:innen, die nur wenig Speicherplatz oder eine langsame Internetverbindung zur Verfügung haben oder für quantitativ arbeitende Forscher:innen, die beim Einlesen der CSV-Dateien Probleme haben.



##  ANALYSE 

Dieses Archiv enthält alle während dem Kompilierungs- und Prüfprozess erstellten Tabellen (CSV) und Diagramme (PDF, PNG) im Original. Sie sind inhaltsgleich mit den in diesem Codebook verwendeten Tabellen und Diagrammen. 

Das PDF-Format eignet sich besonders für die Verwendung in gedruckten Publikationen, das PNG-Format besonders für die Darstellung im Internet. Analyst:innen mit fortgeschrittenen Kenntnissen in R können auch auf den Source Code zurückgreifen. Empfohlen für Nutzer:innen die einzelne Inhalte aus dem Codebook für andere Zwecke (z.B. Präsentationen, eigene Publikationen) weiterverwenden möchten.

**Hilfreich bei der Vorbereitung von Lehre und Forschung**




\newpage





# Variablen
\label{variablen}


## Datenstruktur 

```{r}
str(dt.meta)
```


## Allgemeine Hinweise


- **Doppelte Codierung der Spruchkörper** --- Für viele Urteile sind die Spruchkörper doppelt enthalten, einmal aus der Datenbank (Variable \enquote{spruchkoerper\_db}), einmal durch das Aktenzeichen (Variable \enquote{spruchkoerper\_az}).
- **Fehlende Werte** sind immer mit \enquote{NA} codiert.
- **Strings** können grundsätzlich alle in UTF-8 definierten Zeichen (insbesondere Buchstaben, Zahlen und Sonderzeichen) enthalten.
- Die **Reihenfolge** der Variablen entspricht der im CSV-Datensatz. Der Datensatz wird automatisiert darauf getestet, ob alle Variablen im Datensatz auch in diesem Codebook dokumentiert sind.

\newpage


## ID-Variablen

ID-Variablen stellen verschiedene Identifikatoren für die Entscheidung zur Verfügung, beispielsweise Aktenzeichen oder ECLI.


```{r}

kable(variables.codebook[group == "1_id", .(varname, type, description)],
      format = "latex",
      align = 'P{3.5cm}P{3cm}p{8cm}',
      booktabs = TRUE,
      longtable = TRUE,
      escape = FALSE,
      col.names = c("Variable",
                    "Type",
                    "Description"))  %>% kable_styling(latex_options = "repeat_header")

```

## Text-Variablen

Text-Variablen enthalten den Volltext der Entscheidung, Teilstücke davon (z.B. Leitsätze), den Umfang des Volltextes (Zeichen, Tokens, Typen, Sätze) und dessen Quelle (URLs zu Volltexten).


```{r}

kable(variables.codebook[group == "2_text", .(varname, type, description)],
      format = "latex",
      align = 'P{3.5cm}P{3cm}p{8cm}',
      booktabs = TRUE,
      longtable = TRUE,
      escape = FALSE,
      col.names = c("Variable",
                    "Type",
                    "Description"))  %>% kable_styling(latex_options = "repeat_header")

```



## Thematische Variablen

Thematische Variablen geben Auskunft über eine grobe thematische Zuordnung der Entscheidung, beispielsweise zu Registerzeichen, Verfahrensart, Normen, Vorinstanz.


```{r}

kable(variables.codebook[group == "3_thematic", .(varname, type, description)],
      format = "latex",
      align = 'P{3.5cm}P{3cm}p{8cm}',
      booktabs = TRUE,
      longtable = TRUE,
      escape = FALSE,
      col.names = c("Variable",
                    "Type",
                    "Description"))  %>% kable_styling(latex_options = "repeat_header")

```



## Temporale Variablen

Temporale Variablen bieten Informationen zu wichtigen Zeitpunkten, wie Verkündung der Entscheidung, Veröffentlichung der Entscheidung oder Eingang des Verfahrens.



```{r}

kable(variables.codebook[group == "4_temporal", .(varname, type, description)],
      format = "latex",
      align = 'P{3.5cm}P{3cm}p{8cm}',
      booktabs = TRUE,
      longtable = TRUE,
      escape = FALSE,
      col.names = c("Variable",
                    "Type",
                    "Description"))  %>% kable_styling(latex_options = "repeat_header")

```

## Meta-Variablen

Meta-Variablen beziehen sich auf den Datensatz selbst. Sie dokumentieren Versionsnummer, verschiedene DOIs und die Lizenz des Datensatzes. Streng genommen sind sie innerhalb des Datensatzes Konstanten (weil der Inhalt immer gleich ist) und nur im Vergleich zwischen Datensätzen echte Variablen.



```{r}

kable(variables.codebook[group == "9_meta", .(varname, type, description)],
      format = "latex",
      align = 'P{3.5cm}P{3cm}p{8cm}',
      booktabs = TRUE,
      longtable = TRUE,
      escape = FALSE,
      col.names = c("Variable",
                    "Type",
                    "Description"))  %>% kable_styling(latex_options = "repeat_header")

```








\newpage



# Registerzeichen
 
\label{register}


Die Tabelle der Registerzeichen und der ihnen zugeordneten Verfahrensarten stammt aus dem folgenden Datensatz: \enquote{Seán Fobbe (2021). Aktenzeichen der Bundesrepublik Deutschland (AZ-BRD). Version 1.0.1. Zenodo. DOI: 10.5281/zenodo.4569564.}

Die im Datensatz enthaltenen Registerzeichen wurden jeweils um die runden Klammern bereinigt, um Probleme bei der Nutzung unter Windows zu vermeiden.

Die Bedeutung des Registerzeichens \enquote{ER-S} ist mir nicht klar, aber möglicherweise ist es eine Kombination aus den Registerzeichen \enquote{E}, \enquote{R} und \enquote{S}. Ich arbeite an der Aufklärung.


\vspace{0.5cm}


\ra{1.2}


```{r}
kbl(az.brd[stelle == "BFH" & position == "hauptzeichen",
           .(zeichen_original,bedeutung)],
    format = "latex",
    align = c("P{3cm}",
              "p{11cm}"),
    booktabs = TRUE,
    longtable = TRUE,
    col.names = c("Registerzeichen",
                  "Verfahrensart")) 

```




\newpage

# Linguistische Kennzahlen


## Erläuterung der Kennzahlen und Diagramme

Zur besseren Einschätzung des inhaltlichen Umfangs des Korpus dokumentiere ich an dieser Stelle die Verteilung der Werte für einige klassische linguistische Kennzahlen:

\medskip



\begin{centering}
\begin{longtable}{P{3.5cm}p{10.5cm}}

\toprule

Kennzahl & Definition\\

\midrule

Zeichen & Zeichen entsprechen grob den \emph{Graphemen}, den kleinsten funktionalen Einheiten in einem Schriftsystem. Beispiel: das Wort \enquote{Richterin} besteht aus 9 Zeichen.\\
 
Tokens & Eine beliebige Zeichenfolge, getrennt durch whitespace-Zeichen, d.h. ein Token entspricht in der Regel einem \enquote{Wort}, kann aber auch Zahlen, Sonderzeichen oder sinnlose Zeichenfolgen enthalten, weil es rein syntaktisch berechnet wird.\\
 
Typen & Einzigartige Tokens. Beispiel: wenn das Token \enquote{Finanzrecht} zehnmal in einer Entscheidung vorhanden ist, wird es als ein Typ gezählt.\\
 
Sätze & Entsprechen in etwa dem üblichen Verständnis eines Satzes. Die Regeln für die Bestimmung von Satzanfang und Satzende sind im Detail aber sehr komplex und in \enquote{Unicode Standard: Annex No 29} beschrieben.\\

\bottomrule

\end{longtable}
\end{centering}



Es handelt sich bei den Diagrammen jeweils um \enquote{Density Charts}, die sich besonders dafür eignen die Schwerpunkte von Variablen mit stark schwankenden numerischen Werten zu visualisieren. Die Interpretation ist denkbar einfach: je höher die Kurve, desto dichter sind in diesem Bereich die Werte der Variable. Der Wert der y-Achse kann außer Acht gelassen werden, wichtig sind nur die relativen Flächenverhältnisse und die x-Achse.

 Vorsicht bei der Interpretation: Die x-Achse ist logarithmisch skaliert, d.h. in 10er-Potenzen und damit nicht-linear. Die kleinen Achsen-Markierungen zwischen den Schritten der Exponenten sind eine visuelle Hilfestellung um diese nicht-Linearität zu verstehen.

\bigskip




## Werte der Kennzahlen

```{r}
setnames(lingstats.summary, c("Variable",
                              "Summe",
                              "Min",
                              "Quart1",
                              "Median",
                              "Mittel",
                              "Quart3",
                              "Max"))

kable(lingstats.summary,
      digits = 2,
      format.args = list(big.mark = ","),
      format = "latex",
      booktabs = TRUE,
      longtable = TRUE)
```



## Verteilung Zeichen


```{r, CE-BFH_Density_Zeichen, fig.height = 6, fig.width = 9}
ggplot(data = dt.meta)+
    geom_density(aes(x = zeichen),
                 fill = "#7e0731")+
    scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
                  labels = trans_format("log10", math_format(10^.x)))+
    annotation_logticks(sides = "b")+
    coord_cartesian(xlim = c(1, 10^6))+
    theme_bw()+
    labs(
        title = paste(prefix.figuretitle,
                      "| Verteilung der Zeichen je Dokument"),
        caption = caption,
        x = "Zeichen",
        y = "Dichte"
    )+
    theme(
        text = element_text(size = 14),
        plot.title = element_text(size = 14,
                                  face = "bold"),
        legend.position = "none",
        plot.margin = margin(10, 20, 10, 10)
    )
```



## Verteilung Tokens

```{r,  CE-BFH_Density_Tokens, fig.height = 6, fig.width = 9}
ggplot(data = dt.meta)+
    geom_density(aes(x = tokens),
                 fill = "#7e0731")+
    scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
                  labels = trans_format("log10", math_format(10^.x)))+
    annotation_logticks(sides = "b")+
    coord_cartesian(xlim = c(1, 10^6))+
    theme_bw()+
    labs(
        title = paste(prefix.figuretitle,
                      "| Verteilung der Tokens je Dokument"),
        caption = caption,
        x = "Tokens",
        y = "Dichte"
    )+
    theme(
        text = element_text(size = 14),
        plot.title = element_text(size = 14,
                                  face = "bold"),
        legend.position = "none",
        plot.margin = margin(10, 20, 10, 10)
    )
```


## Verteilung Typen

```{r, CE-BFH_Density_Typen, fig.height = 6, fig.width = 9}
ggplot(data = dt.meta)+
    geom_density(aes(x = typen),
                 fill = "#7e0731")+
    scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
                  labels = trans_format("log10", math_format(10^.x)))+
    annotation_logticks(sides = "b")+
    coord_cartesian(xlim = c(1, 10^6))+
    theme_bw()+
    labs(
        title = paste(prefix.figuretitle,
                      "| Verteilung der Typen je Dokument"),
        caption = caption,
        x = "Typen",
        y = "Dichte"
    )+
    theme(
        text = element_text(size = 14),
        plot.title = element_text(size = 14,
                                  face = "bold"),
        legend.position = "none",
        plot.margin = margin(10, 20, 10, 10)
    )
```



## Verteilung Sätze

```{r, CE-BFH_Density_Saetze, fig.height = 6, fig.width = 9}
ggplot(data = dt.meta)+
    geom_density(aes(x = saetze),
                 fill = "#7e0731")+
    scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
                  labels = trans_format("log10", math_format(10^.x)))+
    annotation_logticks(sides = "b")+
    coord_cartesian(xlim = c(1, 10^6))+
    theme_bw()+
    labs(
        title = paste(prefix.figuretitle,
                      "| Verteilung der Sätze je Dokument"),
        caption = caption,
        x = "Sätze",
        y = "Dichte"
    )+
    theme(
        text = element_text(size = 14),
        plot.title = element_text(size = 14,
                                  face = "bold"),
        legend.position = "none",
        plot.margin = margin(10, 20, 10, 10)
    )
```





# Zitationsnetzwerk des Bundesfinanzhofs (Beta)

## Überblick

Der Datensatz enthält zusätzlich eine spezialisierte Variante, die Zitate des BFH aus den Entscheidungstexten zu seiner eigenen Rechtsprechung extrahiert und in strukturierter Form aufbereitet.

Diese Variante ist noch in der Beta-Testphase. Folgende Rechtsprechungszitate sind enthalten:

- Zitate von Aktenzeichen zu Aktenzeichen
- Zitate von Aktenzeichen zu BFHE

**Achtung:** Zitierende Entscheidungen können nur solche sein, für die im Korpus der Volltext dokumentiert ist (d.h. normalerweise ab 2010). Zitierte Entscheidungen können aus der gesamten Rechtsprechung stammen (d.h. aus allen Jahren).

Zitate unter Angabe des Aktenzeichens sind weniger genau als Zitate zu konkreten Entscheidungen (bei denen Datum und ggf. Kollisionsziffer nötig sind). Sie stellen aber eine gute Näherung dar. Die Auflösung der Zitate auf Entscheidungsebene ist geplant und wird in Zukunft mitveröffentlicht.

BFHE-Zitate können exakt einer zitierten Entscheidung zugeordnet werden. Die Quell-Dokumente sind jedoch nur mit dem Aktenzeichen hinterlegt, um eine Konkordanz mit dem Rest des Datensatzes herzustellen. Die Auflösung von Quell-Dokumenten nach BFHE ist mir leider derzeit nicht möglich, da ich aktuell keine Entsprechungstabelle zwischen amtlichen Sammlungen und Aktenzeichen/Datum-Zitaten habe.


## Technische Hinweise

Das Zitationsnetzwerk wird als GraphML-Datei angeboten und kann z.B. einfach in graphische Software wie Gephi\footnote{\url{https://gephi.github.io/}} importiert und ohne Programmierkenntnisse genutzt werden. Formal handelt sich um einen gewichteten, gerichteten Graphen (Digraph). Die Anzahl der Knoten gibt die Anzahl der BFHE-Entscheidungen und Aktenzeichen mit eingehenden und/oder ausgehenden Zitaten an. Die Anzahl der Kanten gibt die Anzahl der Knoten-Paare mit mindestens einem Zitat an. Die Gewichte der Kanten geben die Anzahl der Zitate zwischen Knoten an. Die Ausgangsstärke gibt die Summe aller einfachen Zitate an.

Beachten Sie auch bitte folgende Punkte:

- Das gesamte Netzwerk ist sehr groß und die Analyse ist daher ohne weitere Einschränkungen rechenintensiv und anspruchsvoll. In der Regel sollten Sie das Netzwerk auf die für Sie interessanten Teile reduzieren.
- Zur Reduktion des Netzwerks auf eine handliche Größe stelle ich v.a. zwei Variablen bereit: den Senat und das Registerzeichen.
- Die Extraktion mit *regular expressions* ist nicht perfekt. Es kann daher sein, dass Zitate fehlen, wenn sie nicht als solche erkannt wurden, wegen Tippfehlern, ungewöhnlichem Textumfeld etc. Es ist aktuell unklar wieviele Zitate fehlen könnten, weil es keinen Goldstandard zum Abgleich gibt. Wenn Ihnen größere Fehlbestände auffallen, melden Sie sich bitte.
- Sie können über die Variable \enquote{bfh-alternative} alle BFHE-Zitate auswählen (TRUE) oder nur Aktenzeichen-Zitate betrachten (FALSE)


\bigskip

\ra{1.1}
```{r}

g <- igraph_citations


dt.g <- data.table(Metric = c("Number of Nodes",
                              "Number of Edges",
                              "Strength (Out)",
                              "Mean Degree",
                              "Max Degree",
                              "Min Degree",
                              "Mean In-Degree",
                              "Max In-Degree",
                              "Min In-Degree",
                              "Mean Out-Degree",
                              "Max Out-Degree",
                              "Min Out-Degree"),
                   Value = c(igraph::vcount(g),
                             igraph::ecount(g),
                             sum(igraph::strength(g, mode = "out")),
                             mean(igraph::degree(g, mode = "all")),
                             max(igraph::degree(g, mode = "all")),
                             min(igraph::degree(g, mode = "all")),
                             mean(igraph::degree(g, mode = "in")),
                             max(igraph::degree(g, mode = "in")),
                             min(igraph::degree(g, mode = "in")),
                             mean(igraph::degree(g, mode = "out")),
                             max(igraph::degree(g, mode = "out")),
                             min(igraph::degree(g, mode = "out"))
                             )
                   )

dt.g.split <- cbind(dt.g[1:6], dt.g[7:12])

kable(dt.g.split,
      digits = 2,
      format.args = list(big.mark = ","),
      format = "latex",
      booktabs = TRUE,
      longtable = TRUE)

```

## Metadaten

Die Knoten des Netzwerks sind mit Metadaten aus dem Hauptdatensatz angereichert. Deshalb sind grundsätzlich nur im Hauptdatensatz vorhandene Aktenzeichen (d.h. solche die in der BFH-Datenbank veröffentlicht sind) mit allen Metadaten verbunden. 

Für alle anderen Zitate konnte ich nur solche Metadaten hinterlegen, die sich aus dem Aktenzeichen (Registerzeichen, Senatsnummer) oder dem BFH-Zitat (BFH ja/nein, Nummer des Bandes) und mit REGEX zu extrahieren waren.

Hinweis: die Variable \enquote{bfhe} gibt an, ob die das Aktenzeichen in der BFH-Datenbank als V- oder NV-Entscheidung markiert ist. Die Variable \enquote{bfhe-alternative} dagegen ist TRUE/FALSE und gibt an, ob das Zitat (d.h. der Name des Knotens) die Zeichenkette \enquote{BFHE} enthält.

Folgende Metadaten-Variablen sind enthalten:

`r sort(vertex_attr_names(igraph_citations))`



## Methodik Aktenzeichen

Dieser Datensatz enthält sowohl zitierte Aktenzeichen (Aktenzeichen-zu-Aktenzeichen-Zitate), als auch Zitate von Aktenzeichen zu BFHE-Zitate (Aktenzeichen-zu-Sammlung-Zitate). 

Aktenzeichen sind verhältnismäßig einfach zu erfassen. Die Funktion *f.citation_network.R* erstellt erstellt eine komplexe REGEX, die jeweils die relevanten Registerzeichen in die Suche aufnimmt. Der Source Code ist zu komplex um ihn hier im Detail zu besprechen, sehen Sie sich bei Interesse bitte die Funktion genauer an.

Um konkrete Entscheidungen zu zitieren müsste zusätzlich zum Aktenzeichen noch das Datum berücksichtigt werden. Weil dies die REGEX deutlich komplizierter macht, ist dieser Schritt noch in Arbeit. Im Datensatz sind allerdings `r round(uniqueN(dt.meta$aktenzeichen)/dt.meta[,.N] * 100, digits = 2)` % aller ausgehenden Aktenzeichen einzigartig (unabhängig vom Datum), sodass das Aktenzeichen eine gute Näherung darstellt.



## Methodik BFHE

Die Zitate zu den amtlichen Sammlungen BGHZ und BGHSt werden aus dem Volltext in einem Zwei-Stufen-Verfahren extrahiert, ähnlich wie in Coupette, *Juristische Netzwerkforschung* (Mohr Siebeck 2019), S. 241--244.

### Erste Stufe

In der **ersten Stufe** werden die Zitierblöcke lokalisiert und aus dem Volltext gesammelt. Es wird die starke Annahme getroffen, dass Zitierblöcke mit \enquote{BFHE} (ignoriert Groß- und Kleinschreibung) eingeleitet werden und nur Whitespace, Zahlen, gewisse Sonderzeichen und gewisse Buchstaben enthalten. 

Zitierblöcke enden in der Regel mit einer runden Klammer, die in der REGEX nicht enthalten ist, um sie als Grenzzeichen zu nutzen. Auch Gleichheitszeichen (=) sind nicht enthalten, damit die REGEX vor einem Hinweis auf einen alternative Abdruck abbricht.

Die konkreten regular expressions (REGEX) sind die folgenden:

```{r echo = TRUE, eval = FALSE}
"BFHE[\\s\\d\\[\\];,\\.<>Rnfu-]+" # BGHZ
```


### Zweite Stufe

In der **zweiten Stufe** werden aus allen Zitierblöcken die einzelnen Zitate extrahiert, standardisiert und mit der Ausgangsentscheidung verbunden. Die Extraktion trifft die starke Annahme, dass eine Entscheidung der amtlichen Sammlungen entweder mit \enquote{BFHE} oder bei einem Mehrfachzitat in einem Zitierblock mit einem Semikolon eingeleitet wird. Folgende REGEX kommen dabei zum Einsatz:


```{r echo = TRUE}
# BGHZ
regex.cite <- paste0("(BFHE|;)\\s*", # hooks
                     "\\d{1,3},\\s*", # Volume
                     "\\d{1,3}") # Page

print(regex.cite)

```

Damit findet man zwei Varianten von Einzelzitaten:

- \enquote{BFHE 248, 287}
- \enquote{; 248, 287}

Die Einzelzitate werden anschließend bereinigt und standardisiert. Zum Ende hin werden Selbstzitate entfernt und Metadaten hinzugefügt.



### Grenzen

Die Extraktion mit regulären Ausdrücken hat Grenzen. Insbesondere folgende Probleme führen zur Nichterkennung von Zitaten:

- Tippfehler (außer Groß- und Kleinschreibung)
- Unregelmäßge Zitierweise
- Verkürzte Schreibweisen, beispielsweise BVerfGE 60, 162: \enquote{BVerfGE 3, 19 (27), 383 (394); 4, 375 (381 f.);} --- das Beispiel stammt aus Coupette (2019: 246)
- Einfügung von Entscheidungsnamen wie in BVerfGE 42, 143: \enquote{BVerfGE 7, 198 (205ff) - Lüth -; 18, 85 (92f); 30, 173 (187f, 196f) - Mephisto -; 32, 311 (316)}  --- das Beispiel stammt aus Coupette (2019: 246)


\newpage


```{r, CE-BFH_Zitatationsnetzwerk_Senat-1_schwarzweiss, fig.width = 28, fig.height = 16, dpi = 150, dev = "png", fig.cap = "Das interne Zitationsnetzwerk (Aktenzeichen) des 1. Senats."}

index <- which(igraph::V(igraph_citations)$spruchkoerper_az == "I")

g <- igraph::subgraph(igraph_citations, index)


ggraph(g, "sugiyama") + 
    geom_edge_diagonal(width = 0.05,
                       colour = "black")+
    geom_node_point(size = 0.5,
                    color = "black")+
    theme_void()+
    labs(
        title = paste(prefix.figuretitle,
                      "| Das interne Zitationsnetzwerk (Aktenzeichen und BFHE) des 1. Senats des Bundesfinanzhofs [Körperschaftsteuer, Außensteuerrecht, Doppelbesteuerung]"),
        caption = caption
    )+
    theme(
        plot.title = element_text(size = 14,
                                  face = "bold",
                                  color = "black"),                        
        plot.background = element_rect(fill = "white"),
        plot.caption = element_text(color = "black"),
        plot.margin = margin(10, 20, 10, 10)
    )

#ggsave("test.png", dev = "png", width = 28, height = 16, dpi = 150)

```

```{r, CE-BFH_Zitatationsnetzwerk_Senat-6_schwarzweiss, fig.width = 28, fig.height = 16, dpi = 150, dev = "png", fig.cap = "Das interne Zitationsnetzwerk (Aktenzeichen) des 6. Senats."}

index <- which(igraph::V(igraph_citations)$spruchkoerper_az == "VI")

g <- igraph::subgraph(igraph_citations, index)


ggraph(g, "sugiyama") + 
    geom_edge_diagonal(width = 0.05,
                       colour = "black")+
    geom_node_point(size = 0.5,
                    color = "black")+
    theme_void()+
    labs(
        title = paste(prefix.figuretitle,
                      "| Das interne Zitationsnetzwerk (Aktenzeichen und BFHE) des 6. Senats des Bundesfinanzhofs [Lohnsteuer, außergewöhnliche Belastungen, Land- und Forstwirtschaft]"),
        caption = caption
    )+
    theme(
        plot.title = element_text(size = 14,
                                  face = "bold",
                                  color = "black"),                        
        plot.background = element_rect(fill = "white"),
        plot.caption = element_text(color = "black"),
        plot.margin = margin(10, 20, 10, 10)
    )



```

\newpage


```{r, CE-BFH_Zitationsnetzwerk_Knotengrad, fig.width = 9, fig.height = 6}


g <- igraph_citations
degree.all <- data.table(prop = degree_distribution(g, mode = "all"))
degree.all$degree <- 1:length(degree.all$prop)



ggplot(data = degree.all) +
    geom_bar(aes(x = degree,
                 y = prop),
             stat = "identity",
             fill = "black",
             color = "black",
             width = 0.5) +
    theme_bw() +
    coord_cartesian(xlim = c(1, 10^2))+
    labs(
        title = paste(prefix.figuretitle,
                      "| Verteilung der Knotengrade bis 100 im Zitationsnetzwerk"),
        caption = caption,
        x = "Knotengrad",
        y = "Anteil"
    )+
    theme(
        text = element_text(size = 13),
        plot.title = element_text(size = 13,
                                  face = "bold"),
        legend.position = "none",
        plot.margin = margin(10, 20, 10, 10)
    )


```



```{r, CE-BFH_Zitationsnetzwerk_Eingangsgrad, fig.width = 9, fig.height = 6}


g <- igraph_citations
degree.in <- data.table(prop = degree_distribution(g, mode = "in"))
degree.in$degree <- 1:length(degree.in$prop)



ggplot(data = degree.in) +
    geom_bar(aes(x = degree,
                 y = prop),
             stat = "identity",
             fill = "black",
             color = "black",
             width = 0.5) +
    theme_bw() +
    coord_cartesian(xlim = c(1, 10^2))+
    labs(
        title = paste(prefix.figuretitle,
                      "| Verteilung der Eingangsgrade bis 100 im Zitationsnetzwerk"),
        caption = caption,
        x = "Eingangsgrad",
        y = "Anteil"
    )+
    theme(
        text = element_text(size = 13),
        plot.title = element_text(size = 13,
                                  face = "bold"),
        legend.position = "none",
        plot.margin = margin(10, 20, 10, 10)
    )




```




# Inhalt des Korpus

## Zusammenfassung

```{r}

dt.summary.docvars <- dt.meta[,
                              lapply(.SD, function(x)unclass(summary(na.omit(x)))),
                              .SDcols = c("entscheidungsjahr",
                                          "eingangsjahr_iso",
                                          "eingangsnummer")]


dt.unique.docvars <- dt.meta[,
                             lapply(.SD, function(x)length(unique(na.omit(x)))),
                             .SDcols = c("entscheidungsjahr",
                                         "eingangsjahr_iso",
                                         "eingangsnummer")]


dt.stats.docvars <- rbind(dt.unique.docvars,
                          dt.summary.docvars)

dt.stats.docvars <- transpose(dt.stats.docvars,
                              keep.names = "names")


setnames(dt.stats.docvars, c("Variable",
                             "Anzahl",
                             "Min",
                             "Quart1",
                             "Median",
                             "Mean",
                             "Quart3",
                             "Max"))



kable(dt.stats.docvars,
      digits = 2,
      format = "latex",
      booktabs = TRUE,
      longtable = TRUE)


```

\vspace{0.5cm}



## Nach Typ der Entscheidung


```{r, CE-BFH_Barplot_Entscheidungstyp, fig.height = 6, fig.width = 9}

freqtable <- f.fast.freqtable(dt.meta,
                                 varlist = "bfhe",
                                 sumrow = TRUE,
                                 output.list = TRUE,
                                 output.kable = FALSE,
                                 output.csv = FALSE,
                                 align = c("p{5cm}"))[[1]][,exactpercent:=NULL]

freqtable.nosum <- freqtable[-.N]



ggplot(data = freqtable.nosum) +
    geom_bar(aes(x = reorder(bfhe,
                             -N),
                 y = N),
             stat = "identity",
             fill = "#7e0731",
             color = "black",
             width = 0.5) +
    theme_bw() +
    labs(
        title = paste(prefix.figuretitle,
                      "| Entscheidungen in amtlicher Sammlung"),
        caption = caption,
        x = "Typ der Entscheidung",
        y = "Entscheidungen"
    )+
    theme(
        text = element_text(size = 14),
        plot.title = element_text(size = 14,
                                  face = "bold"),
        legend.position = "none",
        plot.margin = margin(10, 20, 10, 10)
    )

```

\vspace{0.5cm}


```{r}

kable(freqtable,
      format = "latex",
      align = 'P{3cm}',
      booktabs = TRUE,
      longtable = TRUE,
      col.names = c("Typ",
                    "Entscheidungen",
                    "% Gesamt",
                    "% Kumulativ"))  %>% kable_styling(latex_options = "repeat_header")

```




\newpage


## Nach Spruchkörper (Aktenzeichen)




```{r, CE-BFH_Barplot_Spruchkoerper_AZ, fig.height = 6, fig.width = 9}

freqtable <- f.fast.freqtable(dt.meta,
                                 varlist = "spruchkoerper_az",
                                 sumrow = TRUE,
                                 output.list = TRUE,
                                 output.kable = FALSE,
                                 output.csv = FALSE,
                                 align = c("p{5cm}"))[[1]][,exactpercent:=NULL]

freqtable.nosum <- freqtable[-.N]


ggplot(data = freqtable.nosum) +
    geom_bar(aes(x = reorder(spruchkoerper_az,
                             -N),
                 y = N),
             stat = "identity",
             fill = "#7e0731",
             color = "black",
             width = 0.5) +
    theme_bw() +
    labs(
        title = paste(prefix.figuretitle,
                      "| Entscheidungen je Senat (Aktenzeichen)"),
        caption = caption,
        x = "Senat",
        y = "Entscheidungen"
    )+
    theme(
        text = element_text(size = 14),
        plot.title = element_text(size = 14,
                                  face = "bold"),
        legend.position = "none",
        plot.margin = margin(10, 20, 10, 10)
    )

```

\vspace{0.5cm}


```{r}
kable(freqtable,
      format = "latex",
      align = 'P{3cm}',
      booktabs = TRUE,
      longtable = TRUE,
      col.names = c("Senat",
                    "Entscheidungen",
                    "% Gesamt",
                    "% Kumulativ"))  %>% kable_styling(latex_options = "repeat_header")

```




\newpage


## Nach Registerzeichen



```{r, CE-BFH_Barplot_Registerzeichen, fig.height = 6, fig.width = 9}

freqtable <- f.fast.freqtable(dt.meta,
                                 varlist = "registerzeichen",
                                 sumrow = TRUE,
                                 output.list = TRUE,
                                 output.kable = FALSE,
                                 output.csv = FALSE,
                                 align = c("p{5cm}"))[[1]][,exactpercent:=NULL]

freqtable.nosum <- freqtable[-.N]



ggplot(data = freqtable.nosum) +
    geom_bar(aes(x = reorder(registerzeichen,
                             N),
                 y = N),
             stat = "identity",
             fill = "#7e0731",
             color = "black") +
    scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
                  labels = trans_format("log10", math_format(10^.x)))+
    coord_flip()+
    theme_bw() +
    labs(
        title = paste(prefix.figuretitle,
                      "| Entscheidungen je Registerzeichen"),
        caption = caption,
        x = "Registerzeichen",
        y = "Entscheidungen"
    )+
    theme(
        text = element_text(size = 14),
        plot.title = element_text(size = 14,
                                  face = "bold"),
        legend.position = "none",
        plot.margin = margin(10, 20, 10, 10)
    )
```

\vspace{0.5cm}


```{r}
kable(freqtable,
      format = "latex",
      align = 'P{3cm}',
      booktabs = TRUE,
      longtable = TRUE,
      col.names = c("Registerzeichen",
                    "Entscheidungen",
                    "% Gesamt",
                    "% Kumulativ"))  %>% kable_styling(latex_options = "repeat_header")
```




\newpage


## Nach Entscheidungsjahr



```{r, CE-BFH_Barplot_Entscheidungsjahr, fig.height = 6, fig.width = 9}

freqtable <- f.fast.freqtable(dt.meta,
                              varlist = "entscheidungsjahr",
                              sumrow = TRUE,
                              output.list = TRUE,
                              output.kable = FALSE,
                              output.csv = FALSE,
                              align = c("p{5cm}"))[[1]][,exactpercent:=NULL]

freqtable.nosum <- freqtable[-.N]


ggplot(data = freqtable.nosum) +
    geom_bar(aes(x = entscheidungsjahr,
                 y = N),
             stat = "identity",
             fill = "#7e0731") +
    scale_x_discrete(breaks = seq(2010, 2020, 2))+
    theme_bw() +
    labs(
        title = paste(prefix.figuretitle,
                      "| Entscheidungen je Entscheidungsjahr"),
        caption = caption,
        x = "Entscheidungsjahr",
        y = "Entscheidungen"
    )+
    theme(
        text = element_text(size = 14),
        plot.title = element_text(size = 14,
                                  face = "bold"),
        legend.position = "none",
        plot.margin = margin(10, 20, 10, 10)
    )
```

\vspace{0.5cm}


```{r}
kable(freqtable,
      format = "latex",
      align = 'P{3cm}',
      booktabs = TRUE,
      longtable = TRUE,
      col.names = c("Entscheidungsjahr",
                    "Entscheidungen",
                    "% Gesamt",
                    "% Kumulativ"))  %>% kable_styling(latex_options = "repeat_header")
```



\newpage
## Nach Eingangsjahr (ISO)


```{r}
freqtable <- f.fast.freqtable(dt.meta,
                                 varlist = "eingangsjahr_iso",
                                 sumrow = TRUE,
                                 output.list = TRUE,
                                 output.kable = FALSE,
                                 output.csv = FALSE,
                                 align = c("p{5cm}"))[[1]][,exactpercent:=NULL]

freqtable.nosum <- freqtable[-.N]
```



```{r, CE-BFH_Barplot_EingangsjahrISO, fig.height = 6, fig.width = 9}
ggplot(data = freqtable.nosum) +
    geom_bar(aes(x = eingangsjahr_iso,
                 y = N),
             stat = "identity",
             fill = "#7e0731") +
    scale_x_discrete(breaks = seq(2000, 2020, 5))+
    theme_bw() +
    labs(
        title = paste(prefix.figuretitle,
                      "| Entscheidungen je Eingangsjahr (ISO)"),
        caption = caption,
        x = "Eingangsjahr (ISO)",
        y = "Entscheidungen"
    )+
    theme(
        text = element_text(size = 14),
        plot.title = element_text(size = 14,
                                  face = "bold"),
        legend.position = "none",
        plot.margin = margin(10, 20, 10, 10)
    )

```

\vspace{0.5cm}


```{r}
kable(freqtable,
      format = "latex",
      align = 'P{3cm}',
      booktabs = TRUE,
      longtable = TRUE,
      col.names = c("Eingangsjahr",
                    "Entscheidungen",
                    "% Gesamt",
                    "% Kumulativ"))  %>% kable_styling(latex_options = "repeat_header")
```



## Nach Normen



```{r}

normen.split <- stringi::stri_split(str = dt.meta$normen, regex = "\\|")
normen  <- unlist(normen.split)

dt.normen <- data.table(normen)

freqtable <- f.fast.freqtable(dt.normen,
                              varlist = "normen",
                              sumrow = TRUE,
                              output.list = TRUE,
                              output.kable = FALSE,
                              output.csv = FALSE,
                              align = c("p{5cm}"))[[1]][,exactpercent:=NULL]
## Reduce to Top 50
freqtable.nosum <- freqtable[-.N][order(-N)][1:50]

```



```{r, CE-BFH_Barplot_Normen, fig.height = 14, fig.width = 9}
ggplot(data = freqtable.nosum) +
    geom_bar(aes(x = reorder(normen, N),
                 y = N),
             stat = "identity",
             fill = "#7e0731") +
    coord_flip()+
    theme_bw() +
    labs(
        title = paste(prefix.figuretitle,
                      "| Die 50 wichtigsten Normen"),
        caption = caption,
        x = "Normen",
        y = "Entscheidungen"
    )+
    theme(
        text = element_text(size = 14),
        plot.title = element_text(size = 14,
                                  face = "bold"),
        legend.position = "none",
        plot.margin = margin(10, 20, 10, 10)
    )

```


\vspace{0.5cm}


```{r}
kable(freqtable.nosum[,cumulpercent:=NULL],
      format = "latex",
      align = 'P{4cm}',
      booktabs = TRUE,
      longtable = TRUE,
      col.names = c("Normen",
                    "Entscheidungen",
                    "% Gesamt"))  %>% kable_styling(latex_options = "repeat_header")
```






# Dateigrößen


```{r, CE-BFH_Density_Dateigroessen_PDF, fig.height = 6, fig.width = 9}


pdf.MB <- file.size(files.pdf) / 10^6


dt.plot <- data.table(pdf.MB)

ggplot(data = dt.plot,
       aes(x = pdf.MB)) +
    geom_density(fill = "#7e0731") +
    scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
                  labels = trans_format("log10", math_format(10^.x)))+
    annotation_logticks(sides = "b")+
    theme_bw() +
    labs(
        title = paste(prefix.figuretitle,
                      "| Verteilung der Dateigrößen (PDF)"),
        caption = caption,
        x = "Dateigröße in MB",
        y = "Dichte"
    )+
    theme(
        text = element_text(size = 14),
        plot.title = element_text(size = 14,
                                  face = "bold"),
        legend.position = "none",
        panel.spacing = unit(0.1, "lines"),
        plot.margin = margin(10, 20, 10, 10)
    )
    
```




```{r, CE-BFH_Density_Dateigroessen_TXT, fig.height = 6, fig.width = 9}

txt.MB <- file.size(files.txt) / 10^6

dt.plot <- data.table(txt.MB)

ggplot(data = dt.plot,
       aes(x = txt.MB)) +
    geom_density(fill = "#7e0731") +
    scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
                  labels = trans_format("log10", math_format(10^.x)))+
    annotation_logticks(sides = "b")+
    theme_bw() +
    labs(
        title = paste(prefix.figuretitle,
                      "| Verteilung der Dateigrößen (TXT)"),
        caption = caption,
        x = "Dateigröße in MB",
        y = "Dichte"
    )+
    theme(
        text = element_text(size = 14),
        plot.title = element_text(size = 14,
                                  face = "bold"),
        legend.position = "none",
        panel.spacing = unit(0.1, "lines"),
        plot.margin = margin(10, 20, 10, 10)
    )

```


```{r, CE-BFH_Density_Dateigroessen_HTML, fig.height = 6, fig.width = 9}

html.MB <- file.size(files.html) / 10^6

dt.plot <- data.table(html.MB)

ggplot(data = dt.plot,
       aes(x = html.MB)) +
    geom_density(fill = "#7e0731") +
    scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
                  labels = trans_format("log10", math_format(10^.x)))+
    annotation_logticks(sides = "b")+
    theme_bw() +
    labs(
        title = paste(prefix.figuretitle,
                      "| Verteilung der Dateigrößen (HTML)"),
        caption = caption,
        x = "Dateigröße in MB",
        y = "Dichte"
    )+
    theme(
        text = element_text(size = 14),
        plot.title = element_text(size = 14,
                                  face = "bold"),
        legend.position = "none",
        panel.spacing = unit(0.1, "lines"),
        plot.margin = margin(10, 20, 10, 10)
    )

```








# Kryptographische Signaturen


## Zwei-Phasen-Signatur

Die Integrität und Echtheit der einzelnen Archive des Datensatzes sind durch eine Zwei-Phasen-Signatur sichergestellt.

In **Phase I** werden während der Kompilierung für jedes ZIP-Archiv, das Codebook und die Robustness Checks Hash-Werte in zwei verschiedenen Verfahren (SHA2-256 und SHA3-512) berechnet und in einer CSV-Datei dokumentiert.

In **Phase II** werden diese CSV-Datei und der Compilation Report mit meinem persönlichen geheimen GPG-Schlüssel signiert. Dieses Verfahren stellt sicher, dass die Kompilierung von jedermann durchgeführt werden kann, insbesondere im Rahmen von Replikationen, die persönliche Gewähr für Ergebnisse aber dennoch vorhanden bleibt.


## Persönliche GPG-Signatur

Die während der Kompilierung des Datensatzes erstellte CSV-Datei mit den Hash-Prüfsummen und der Compilation Report sind mit meiner persönlichen GPG-Signatur versehen. Der mit dieser Version korrespondierende Public Key ist sowohl mit dem Datensatz als auch mit dem Source Code hinterlegt. Er hat folgende Kenndaten:
 
 **Name:** Sean Fobbe (fobbe-data@posteo.de)
 
 **Fingerabdruck:** FE6F B888 F0E5 656C 1D25  3B9A 50C4 1384 F44A 4E42





\newpage


```{r, results = "asis"}
cat(readLines(tar_read(changelog)),
    sep = "\n")

```







# Parameter für strenge Replikationen


```{r}
system2("openssl", "version", stdout = TRUE)

sessionInfo()

```


# Literaturverzeichnis
